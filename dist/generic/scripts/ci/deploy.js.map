{
  "version": 3,
  "sources": ["scripts/ci/deploy.ts", "ops/aws/src/radical-stack/Config.ts", "server/src/config/MagicEnv.ts", "server/src/config/Env.ts", "scripts/ci/lib/helpers.ts", "common/util/sleep.ts"],
  "sourcesContent": ["#!/usr/bin/env -S node --enable-source-maps\n\nimport { inspect, promisify } from 'util';\n\nimport 'dotenv/config.js';\nimport * as fs from 'fs/promises';\nimport * as zlib from 'zlib';\nimport * as autoscaling from '@aws-sdk/client-auto-scaling';\nimport * as cloudfront from '@aws-sdk/client-cloudfront';\nimport * as ec2 from '@aws-sdk/client-ec2';\nimport * as ecr from '@aws-sdk/client-ecr';\nimport * as elbv2 from '@aws-sdk/client-elastic-load-balancing-v2';\nimport Docker from 'dockerode';\nimport { decode } from 'js-base64';\nimport type * as pg from 'pg';\nimport yargs from 'yargs';\n\nimport { AWS_REGION } from 'ops/aws/src/radical-stack/Config.ts';\nimport env from 'server/src/config/Env.ts';\nimport {\n  runCommandLine,\n  connectToDatabase,\n  postMessageFactory,\n  sleepSeconds,\n} from 'scripts/ci/lib/helpers.ts';\n\nfunction log(...stuff: any[]): void {\n  const ts = new Date().toISOString();\n  console.log(`[${ts}]`, ...stuff);\n}\n\nfunction logError(...stuff: any[]) {\n  log('ERROR:', ...stuff);\n}\n\n// This script may return these exit codes:\n// 0: success! Deployment complete.\n// 1: error!\n// 2: deployment skipped (`automaticDeploy` switched off and `--force` option\n// wasn't given)\n\n// No easy way to retrieve these AWS ids, so they are defined here as constants,\n// as looked up on the AWS console.\nconst CONFIG = {\n  prod: {\n    targetGroups: {\n      api: 'arn:aws:elasticloadbalancing:eu-west-2:869934154475:targetgroup/prodServerAPITargetGroup/372ac2f0bcb95756',\n      console:\n        'arn:aws:elasticloadbalancing:eu-west-2:869934154475:targetgroup/prodServerConsoleTargetGroup/4ba4279d4c45284b',\n      docs: 'arn:aws:elasticloadbalancing:eu-west-2:869934154475:targetgroup/prodServerDocsTargetGroup/f993310fd5f1062e',\n      admin:\n        'arn:aws:elasticloadbalancing:eu-west-2:869934154475:targetgroup/prodServerAdminTargetGroup/7f29f18a9aa7f7f2',\n    },\n    cloudFrontDistributionID: 'E2P1Z0TBFUA575',\n  },\n  staging: {\n    targetGroups: {\n      api: 'arn:aws:elasticloadbalancing:eu-west-2:869934154475:targetgroup/stagingServerAPITargetGroup/8819231831fc0427',\n      console:\n        'arn:aws:elasticloadbalancing:eu-west-2:869934154475:targetgroup/stagingServerConsoleTargetGroup/0fab9fe8f850d0ac',\n      docs: 'arn:aws:elasticloadbalancing:eu-west-2:869934154475:targetgroup/stagingServerDocsTargetGroup/562c2760e4255468',\n      admin:\n        'arn:aws:elasticloadbalancing:eu-west-2:869934154475:targetgroup/stagingServerAdminTargetGroup/dde44005f9f01b4c',\n    },\n    cloudFrontDistributionID: 'E2EZOYZW0TRYBC',\n  },\n  loadtest: {\n    targetGroups: {\n      api: 'arn:aws:elasticloadbalancing:eu-west-2:869934154475:targetgroup/loadtestServerAPITargetGroup/7c337619a9e59828',\n    },\n    cloudFrontDistributionID: 'E32RS03NTNGW0X',\n  },\n};\n\nconst argv = yargs(process.argv.slice(2))\n  .option('pullImage', {\n    type: 'string',\n    description: 'Docker image to pull and deploy',\n    default: '869934154475.dkr.ecr.eu-west-2.amazonaws.com/server:latest',\n  })\n  .option('pushOnSuccess', {\n    type: 'string',\n    description: 'Docker tag to push after successful deploy',\n  })\n  .option('force', {\n    type: 'boolean',\n    description: 'deploy even if \"automaticDeploy\" is off',\n  })\n  .option('unattended', {\n    type: 'boolean',\n    description:\n      'flag that the script is executed unattendedly (by a build plan or cron job), results in posting extra messages to Slack',\n  })\n  .help()\n  .alias('help', 'h').argv;\n\nasync function main(): Promise<number> {\n  const { CORD_TIER: tier } = env;\n\n  if (tier !== 'staging' && tier !== 'prod' && tier !== 'loadtest') {\n    throw new Error('tier must be prod, staging, or loadtest');\n  }\n\n  // Connect to the database for a few bits and pieces\n  const db = await connectToDatabase();\n\n  // Get the contents of the heimdall table as one JavaScript object\n  const opsConfig: Record<string, any> =\n    (\n      await db.query(\n        `SELECT json_object_agg(key, value) AS config\n         FROM cord.heimdall WHERE tier=$1;`,\n        [tier],\n      )\n    )?.rows[0]?.config ?? {};\n\n  // Get us a function to post error messages to the Slack ops channel\n  const postErrorMessage = await postMessageFactory(\n    env.CORD_OPS_SLACK_CHANNEL_ID,\n  );\n\n  const postInfoMessage = await postMessageFactory(\n    env.PROD_CHANGES_SLACK_CHANNEL_ID,\n  );\n\n  try {\n    const exitCode = await deployTier(\n      tier,\n      postErrorMessage,\n      postInfoMessage,\n      opsConfig,\n      db,\n    );\n    return exitCode;\n  } catch (err) {\n    await postErrorMessage(`ERROR: push to ${tier} failed with an error\n\\`\\`\\`\n${inspect(err, false, 10, false)}\n\\`\\`\\``);\n    throw err;\n  }\n}\n\nasync function deployTier(\n  tier: 'prod' | 'staging' | 'loadtest',\n  postErrorMessage: (text: string) => Promise<void>,\n  postInfoMessage: (text: string) => Promise<void>,\n  opsConfig: Record<string, any>,\n  db: pg.Client,\n) {\n  log(`Deploying to ${tier} tier`);\n  log(`Arguments: ${JSON.stringify(argv, null, 2)}`);\n\n  const asClient = new autoscaling.AutoScalingClient({ region: AWS_REGION });\n  const ec2Client = new ec2.EC2Client({ region: AWS_REGION });\n  const ecrClient = new ecr.ECRClient({ region: AWS_REGION });\n  const elbv2Client = new elbv2.ElasticLoadBalancingV2Client({\n    region: AWS_REGION,\n  });\n  // API client for local Docker (the one on the machine running this script)\n  const localDocker = new Docker();\n\n  // Get a login token we can use for docker pull/push operations\n  const ecrAuth = await getEcrAuth(ecrClient);\n\n  // Pull the image we want to deploy. In automatic deploys this should be a\n  // no-op, because we would have built this image on the same machine as the\n  // script is running on. However, when running manually, we might need to pull\n  // first.\n  await dockerPull(localDocker, argv.pullImage, ecrAuth);\n\n  // Now that we have pulled the image, we *should* have a repo digest, i.e. an\n  // identifier for this specific image that keeps referring to the image even\n  // if the tag (e.g. \"latest\") is updated. If Docker doesn't give us a repo\n  // digest here, we just continue with the image identifier that we got from\n  // the command line.\n  const imageInfo = await localDocker.getImage(argv.pullImage).inspect();\n  const imageName = imageInfo.RepoDigests[0] ?? argv.pullImage;\n  const imageLabels: Record<string, string | undefined> =\n    imageInfo.Config.Labels;\n  const gitCommitHash = imageLabels['com.cord.git-commit-hash'];\n  const gitCommitTitle = imageLabels['com.cord.git-commit-title'];\n  const packageVersion = imageLabels['com.cord.version'];\n  log(\n    `Using Docker image ${imageName} - git commit hash ${gitCommitHash} - package version ${packageVersion}`,\n  );\n\n  // We have obtained information on the image we are about to deploy, but stop\n  // here if automatic deployments are switched off and this script wasn't\n  // passed the `--force` option.\n  if (!argv.force && !opsConfig.automaticDeploy) {\n    log(\n      \"Automatic deploys are switched off. Use '--force' to deploy nonetheless.\",\n    );\n    if (argv.unattended) {\n      await postErrorMessage(`*NOT* redeploying ${tier} because automatic deployment is switched off\n\u2022 Git commit: ${\n        gitCommitHash\n          ? `<https://github.com/getcord/monorepo/commit/${gitCommitHash}|${gitCommitHash.substr(\n              0,\n              10,\n            )}>`\n          : 'unknown'\n      } ${gitCommitTitle || ''}\n\u2022 Package version: ${packageVersion}\n\u2022 Image: \\`${imageName}\\`\n\u2022 Activate automatic deploys: https://${env.ADMIN_SERVER_HOST}/heimdall\n\u2022 Manual deploy: \\`scripts/manual-deploy.sh ${tier} '${imageName}'\\``);\n    }\n    return 2;\n  }\n\n  // We are going ahead with the deploy. At this point we create a row in the\n  // cord.deploys table.\n  const {\n    rows: [{ id: deployID }],\n  } = await db.query<{ id: string }>(\n    `INSERT INTO cord.deploys (\"tier\", \"gitCommitHash\", \"dockerImage\", \"packageVersion\")\n     VALUES ($1,$2,$3,$4)\n     RETURNING id;`,\n    [tier, gitCommitHash ?? null, imageName, packageVersion ?? null],\n  );\n  log(`Added deploy '${deployID}' to cord.deploys table`);\n\n  await (async () => {\n    // Retrieve a list of EC2 instances in the autoscaling group. Those are the\n    // ones we are going to deploy to.\n    const instances = await getAutoscalingGroupInstances(\n      `${tier}-server`,\n      asClient,\n      ec2Client,\n    );\n\n    log('EC2 instances:');\n    for (const i of instances) {\n      log(`  * ${i.InstanceId} (${i.PrivateDnsName})`);\n    }\n\n    // Pull the Docker container on all instances\n    await Promise.all(\n      instances.map(async (instance) => {\n        log(`docker pull on ${instance.InstanceId}`);\n        const remoteDocker = new Docker({\n          host: instance.PrivateDnsName!,\n          port: 2375,\n          protocol: 'http',\n        });\n        log(`docker prune on ${instance.InstanceId}`);\n        // Clean up old images\n        await remoteDocker\n          .pruneImages({\n            filters: JSON.stringify({\n              until: { '3h': true },\n              dangling: { false: true },\n            }),\n          })\n          .catch(log);\n        log(`docker pull image ${imageName} on ${instance.InstanceId}`);\n        await dockerPull(remoteDocker, imageName, ecrAuth);\n        if (argv.pullImage !== imageName) {\n          log(`docker tag ${imageName} as ${argv.pullImage}`);\n\n          // `argv.pullImage` is the image name passed to this script. We\n          // resolve that into a repo digest above, which we use on each\n          // instance to make extra sure we're deploying the same image\n          // everywhere. The two may be the same (if the script was started with\n          // a repo digest in the first place), but if they are not, we tag the\n          // image we pulled (by repo disgest) with the name that was passed to\n          // the script. For example: if the script is started with a image name\n          // like '.../server:latest`, then we resolve it to a concrete repo\n          // digest once above, we pull that image by digest here on each\n          // instance, and then tag it with given name to update the tag\n          // ('latest' in this example) on the instance.\n          // We could also just pull 'latest' on each instance, but this way\n          // it's just that little bit safer (e.g. if the 'latest' tag get\n          // updated while this script is running)\n          await dockerTag(remoteDocker, imageName, argv.pullImage);\n        }\n\n        log(`finished docker pull on ${instance.InstanceId}`);\n      }),\n    );\n\n    // Now it's time to redeploy all instances\n\n    for (const instance of instances) {\n      log(`\\n\\nInstance: ${instance.InstanceId} (${instance.PrivateDnsName})`);\n\n      // Check the instance health (according to the load balancer)\n      let instanceHealth = (\n        await getInstanceHealth(CONFIG[tier].targetGroups.api, elbv2Client)\n      )[instance.InstanceId!];\n\n      if (instanceHealth !== 'healthy') {\n        // If we are not healthy to begin with, we better not touch this instance\n        log(`Skipping - instance health is ${instanceHealth}`);\n        void postErrorMessage(`During deployment to ${tier}, skipping an instance due to its health status\n\\`\\`\\`\nInstance ID: ${instance.InstanceId}\nHost name: ${instance.PrivateDnsName}\nHealth status: ${instanceHealth}\n\\`\\`\\`\n`);\n        continue;\n      }\n\n      // Deregister this instance from the load balancer.\n      for (const [name, arn] of Object.entries(CONFIG[tier].targetGroups)) {\n        do {\n          log(`Deregistering from load balancer ${name} target group...`);\n          await elbv2Client.send(\n            new elbv2.DeregisterTargetsCommand({\n              TargetGroupArn: arn,\n              Targets: [{ Id: instance.InstanceId! }],\n            }),\n          );\n\n          // Wait one second before checking instance health again\n          await sleepSeconds(1);\n\n          instanceHealth = (await getInstanceHealth(arn, elbv2Client))[\n            instance.InstanceId!\n          ];\n          log(`Instance health is now: ${instanceHealth}`);\n        } while (instanceHealth === 'healthy');\n      }\n\n      // Despite the above checks, we still see that requests to our API can\n      // fail with an error 502 during deployment. Adding an extra delay between\n      // removing an instance from the load balancer and shutting down the\n      // instance seems to solve this reliably.\n\n      if (process.env.ACCELERATE_DEPLOY === 'true') {\n        log('Skipping 30 second pause because ACCELERATE_DEPLOY is true');\n      } else {\n        log('Pausing for 30 seconds to help settle load balancer state');\n        await sleepSeconds(30);\n        log('Continuing...');\n      }\n\n      // Connect to Docker on the instance, stop and remove the current `server`\n      // container\n      const remoteDocker = new Docker({\n        host: instance.PrivateDnsName!,\n        port: 2375,\n        protocol: 'http',\n      });\n\n      try {\n        await remoteDocker\n          .getContainer('server')\n          .update({ RestartPolicy: { Name: '' } });\n      } catch (err) {\n        log(\n          'Updating the restart policy of the existing server container failed:',\n          err,\n        );\n      }\n\n      await drainServer(instance.PrivateDnsName!);\n\n      try {\n        await remoteDocker.getContainer('server').stop();\n        await remoteDocker.getContainer('server').remove();\n      } catch (err) {\n        // If we cannot stop/remove the container, it might just be because it\n        // wasn't running. If that's the case we can still go ahead and start\n        // the server on this instance.\n\n        log(`Could not stop/remove existing container on instance:`, err);\n      }\n\n      // Create and then start the new server container\n      const container = await remoteDocker.createContainer({\n        Image: imageName,\n        name: 'server',\n        AttachStdin: false,\n        AttachStdout: false,\n        AttachStderr: false,\n        Env: [`CORD_TIER=${tier}`],\n        HostConfig: {\n          NetworkMode: 'host',\n          RestartPolicy: { Name: 'always' },\n        },\n      });\n      await container.start();\n\n      // Wait for the server to be up and running and ready to serve requests\n      await waitForServerInit(instance.PrivateDnsName!);\n\n      // Register this instance with the load balancer\n      await Promise.all(\n        Object.values(CONFIG[tier].targetGroups).map((arn) =>\n          elbv2Client.send(\n            new elbv2.RegisterTargetsCommand({\n              TargetGroupArn: arn,\n              Targets: [{ Id: instance.InstanceId! }],\n            }),\n          ),\n        ),\n      );\n\n      // Wait for this instance to successfully register with the load balancer\n      // before moving on to refreshing the next instance\n      for (;;) {\n        await sleepSeconds(3);\n        instanceHealth = (\n          await getInstanceHealth(CONFIG[tier].targetGroups.api, elbv2Client)\n        )[instance.InstanceId!];\n\n        log(`Instance health: ${instanceHealth}`);\n\n        // Instance health should be 'initial' while it's registering and\n        // 'healthy' when it's registered It may enter another state e.g. if at\n        // that moment the scaling group decides to cut the instance In which\n        // case, move on to the next instance to avoid getting stuck on the dying\n        // instance\n        if (instanceHealth === 'healthy') {\n          log('Instance is back online!');\n          break;\n        } else if (instanceHealth !== 'initial') {\n          log(\n            `Instance is in an unexpected state (${instanceHealth}) - moving on to next instance`,\n          );\n          void postErrorMessage(`During deployment to ${tier}, instance in unexpected health state after server restart\n\\`\\`\\`\nInstance ID: ${instance.InstanceId}\nHost name: ${instance.PrivateDnsName}\nHealth status: ${instanceHealth}\n\\`\\`\\`\n`);\n          break;\n        }\n      }\n    }\n\n    // Job done. Let's post about it!\n    let msg = `Redeployed ${tier}: ${gitCommitTitle || ''}${\n      gitCommitHash\n        ? ` (<https://github.com/getcord/monorepo/commit/${gitCommitHash}|${gitCommitHash.substr(\n            0,\n            10,\n          )}>)`\n        : ''\n    }\n\u2022 Package version: ${packageVersion}\n\u2022 Image: \\`${imageName}\\``;\n\n    try {\n      const compress = promisify(zlib.brotliCompress);\n      const sdk = await fs.readFile(\n        `dist/${tier}/external/sdk/v1/sdk.latest.js`,\n      );\n      const compressed = await compress(sdk);\n\n      const sdkBytes = sdk.length;\n      const sdkCompressedBytes = compressed.length;\n\n      await db.query(\n        'UPDATE cord.deploys SET \"sdkBytes\"=$1, \"sdkCompressedBytes\"=$2 WHERE id=$3',\n        [sdkBytes, sdkCompressedBytes, deployID],\n      );\n      msg += `\n\u2022 SDK size: ${sdkBytes} bytes, ${sdkCompressedBytes} bytes compressed`;\n    } catch (err) {\n      log('Failed to estimate sdk size', err);\n    }\n\n    await postInfoMessage(msg);\n    // We should catch any exceptions thrown by the following code, because if\n    // we don't we will post the generic \"push failed\" error message to Slack.\n\n    // Finally, upload static content to S3 and tell CloudFront to invalidate its\n    // caches.\n    try {\n      log('Upload static content to S3');\n      await Promise.all([\n        runCommandLine('aws', [\n          's3',\n          'cp',\n          '--recursive',\n          '--exclude',\n          '*.js',\n          `dist/${tier}/external/`,\n          `s3://${env.APP_SERVER_HOST}/`,\n        ]),\n        runCommandLine('aws', [\n          's3',\n          'cp',\n          '--recursive',\n          '--exclude',\n          '*',\n          '--include',\n          '*.js',\n          '--content-type',\n          'application/javascript; charset=utf-8',\n          `dist/${tier}/external/`,\n          `s3://${env.APP_SERVER_HOST}/`,\n        ]),\n      ]).then((codes) => {\n        if (codes[0] !== 0 || codes[1] !== 0) {\n          throw new Error(`'aws s3 cp' failed with exit code ${codes}`);\n        }\n      });\n    } catch (err) {\n      await postErrorMessage(`Publishing assets on S3 failed with error\n\\`\\`\\`\n${inspect(err, false, 10, false)}\n\\`\\`\\``);\n    }\n\n    // Invalidate S3 CloudFront\n    log('Invalidate S3 CloudFront');\n\n    try {\n      await retryOnError(\n        'Invalidating S3 CloudFront',\n        async () => {\n          const cloudfrontClient = new cloudfront.CloudFrontClient({\n            region: AWS_REGION,\n          });\n\n          const invalidation = await cloudfrontClient.send(\n            new cloudfront.CreateInvalidationCommand({\n              DistributionId: CONFIG[tier].cloudFrontDistributionID,\n              InvalidationBatch: {\n                Paths: { Quantity: 1, Items: ['/*'] },\n                CallerReference: `deploy-${Date.now()}`,\n              },\n            }),\n          );\n          log(\n            `Created CloudFront invalidation (id: ${invalidation.Invalidation?.Id})`,\n          );\n        },\n        {\n          retries: 10,\n          retryIf: (err) => err.Code === 'ServiceUnavailable',\n        },\n      );\n    } catch (err) {\n      await postErrorMessage(`Invalidating S3 CloudFront failed\n\\`\\`\\`\n${inspect(err, false, 10, false)}\n\\`\\`\\``);\n      // Continue the script anyway, this isn't a major problem\n    }\n\n    // If requested on the command line, tag the deployed image. This is useful,\n    // e.g. when we are deploying to staging to keep updating the \"staging\" tag in\n    // the Docker registry to point to the latest image that got successfully\n    // deployed to staging.\n    if (argv.pushOnSuccess) {\n      try {\n        await dockerTag(localDocker, imageName, argv.pushOnSuccess);\n\n        await localDocker\n          .getImage(argv.pushOnSuccess)\n          .push({ authconfig: ecrAuth } as any);\n      } catch (err) {\n        await postErrorMessage(`Updating the Docker tag '${\n          argv.pushOnSuccess\n        }' failed\n  \\`\\`\\`\n  ${inspect(err, false, 10, false)}\n  \\`\\`\\``);\n      }\n    }\n\n    await postInfoMessage('Deployment procedure finished');\n  })().then(\n    () =>\n      db.query(\n        `UPDATE cord.deploys SET \"deployFinishTime\"=NOW(), success=TRUE WHERE id=$1;`,\n        [deployID],\n      ),\n    async (error) => {\n      let errorString = '';\n      try {\n        errorString = inspect(error);\n      } catch (_) {\n        errorString = `${error}`;\n      }\n      await db.query(\n        `UPDATE cord.deploys SET \"deployFinishTime\"=NOW(), success=FALSE, error=$1 WHERE id=$2;`,\n        [errorString, deployID],\n      );\n      return await Promise.reject(error);\n    },\n  );\n\n  // Finally, just do an instance refresh for the async worker, to get it\n  // replaced with the current version. (Before triggering an instance refresh,\n  // cancel any ongoing ones.)\n  await asClient\n    .send(\n      new autoscaling.CancelInstanceRefreshCommand({\n        AutoScalingGroupName: `${tier}-asyncWorker`,\n      }),\n    )\n    // Ignore ActiveInstanceRefreshNotFound errors\n    .catch((err) =>\n      err.Error?.Code === 'ActiveInstanceRefreshNotFound'\n        ? null\n        : Promise.reject(err),\n    );\n\n  await asClient.send(\n    new autoscaling.StartInstanceRefreshCommand({\n      AutoScalingGroupName: `${tier}-asyncWorker`,\n    }),\n  );\n\n  return 0;\n}\n\n/**\n * Obtain a list of ec2.Instance objects for a given autoscaling group name\n */\nasync function getAutoscalingGroupInstances(\n  autoScalingGroupName: string,\n  asClient: autoscaling.AutoScalingClient,\n  ec2Client: ec2.EC2Client,\n) {\n  const { AutoScalingInstances: asInstances } = await asClient.send(\n    new autoscaling.DescribeAutoScalingInstancesCommand({}),\n  );\n  const instanceIDs = (asInstances ?? [])\n    .filter(\n      (instance) =>\n        instance.AutoScalingGroupName === autoScalingGroupName &&\n        instance.LifecycleState === 'InService',\n    )\n    .map((instance) => instance.InstanceId)\n    .filter((x?: string): x is string => x !== undefined);\n\n  const response = await ec2Client.send(\n    new ec2.DescribeInstancesCommand({ InstanceIds: instanceIDs }),\n  );\n\n  return (\n    (response.Reservations ?? [])\n      .map((reservation) => reservation.Instances ?? [])\n      .flat()\n      // only return instances that have these fields\n      .filter(({ InstanceId, PrivateDnsName }) => InstanceId && PrivateDnsName)\n  );\n}\n\n/**\n * Obtain auth object for Docker pull\n */\nasync function getEcrAuth(ecrClient: ecr.ECRClient) {\n  const ecrAuthToken = await ecrClient.send(\n    new ecr.GetAuthorizationTokenCommand({}),\n  );\n  const token = ecrAuthToken.authorizationData?.[0].authorizationToken;\n\n  if (!token) {\n    throw new Error('Could not obtain ECR login credentials');\n  }\n\n  const f = decode(token).split(':');\n\n  if (f.length !== 2) {\n    throw new Error('Invalid ECR login credentials');\n  }\n\n  return { username: f[0], password: f[1] };\n}\n\n/**\n * Pull an image from a remote Docker repository\n *\n * The Dockerode API is a bit awkward here: since we want to pass authentication\n * details, we must provide a callback instead of getting a promise returned.\n * This function wraps that awkward API to reduce code clutter.\n */\nfunction dockerPull(\n  docker: Docker,\n  repoTag: string,\n  auth: { username: string; password: string },\n): Promise<void> {\n  return retryOnError(\n    'dockerPull',\n    () =>\n      new Promise<void>((resolve, reject) =>\n        docker.pull(\n          repoTag,\n          {},\n          (err, stream: NodeJS.ReadableStream | undefined) => {\n            if (stream && !err) {\n              let error: any = undefined;\n\n              // Discard all data. If we don't register this event handler, the\n              // stream just blocks.\n              stream.on('data', (data: Buffer) => {\n                if (error === undefined) {\n                  try {\n                    const parsed = JSON.parse(data.toString('utf-8'));\n                    if (parsed.error) {\n                      error = new Error(parsed.error);\n                    }\n                    // eslint-disable-next-line @typescript-eslint/no-shadow -- Disabling for pre-existing problems. Please do not copy this comment, and consider fixing this one!\n                  } catch (err: any) {\n                    error = err;\n                  }\n                }\n              });\n              stream.once('end', () => {\n                if (error !== undefined) {\n                  reject(error);\n                } else {\n                  resolve();\n                }\n              });\n            } else {\n              reject(err);\n            }\n          },\n          auth,\n        ),\n      ),\n    {\n      retryIf: (err) => err.statusCode === 404,\n    },\n  );\n}\n\n/**\n * Tag a Docker image\n */\nasync function dockerTag(\n  docker: Docker,\n  existingImage: string,\n  newTag: string,\n) {\n  // If \"newTag\" is not of the form \"repo:tag\", then we can't add that tag. We\n  // can just silently ignore this case here.\n\n  const match = /^(?<repo>.*):(?<tag>.*)$/.exec(newTag);\n  if (match && match.groups) {\n    const { repo, tag } = match.groups;\n    await docker.getImage(existingImage).tag({ repo, tag });\n  }\n}\n\nasync function getInstanceHealth(\n  targetGroupArn: string,\n  elbv2Client: elbv2.ElasticLoadBalancingV2Client,\n) {\n  const response = await elbv2Client.send(\n    new elbv2.DescribeTargetHealthCommand({\n      TargetGroupArn: targetGroupArn,\n    }),\n  );\n  return Object.fromEntries<string>(\n    (response.TargetHealthDescriptions ?? [])\n      .map((hd) => [hd.Target?.Id, hd.TargetHealth?.State])\n      .filter((x: any): x is [string, string] => x[0] && x[1]),\n  );\n}\n\nasync function drainServer(hostname: string) {\n  const port = Number(env.STATUS_SERVER_PORT);\n\n  if (!Number.isNaN(port)) {\n    log('Contacting instance and requesting graceful shutdown');\n    const response = await fetch(\n      `http://${hostname}:${env.STATUS_SERVER_PORT}/drain-and-wait`,\n      {\n        method: 'POST',\n        // Don't wait longer than one minute here!\n        signal: AbortSignal.timeout(60 * 1000),\n      },\n    ).catch((err) => {\n      logError(err);\n      return null;\n    });\n\n    if (\n      response &&\n      response.status === 200 &&\n      (await response.text()) === 'terminating'\n    ) {\n      // All is well, we can return immediately\n      log('Server terminated gracefully');\n      return;\n    }\n  }\n\n  // We couldn't connect to the server, or requesting the draining somehow\n  // failed (or timed out). Let's wait another 10s and hope for the best.\n  log(`Could not trigger graceful shutdown of ${hostname} - waiting 10s`);\n  await sleepSeconds(10);\n}\n\nasync function waitForServerInit(hostname: string) {\n  const port = Number(env.STATUS_SERVER_PORT);\n\n  if (Number.isNaN(port)) {\n    log(\n      `Server status port not configured - cannot check for initialisation - waiting 10s and hoping for the best`,\n    );\n    return await sleepSeconds(10);\n  }\n\n  // Contact the newly started server's status port and request\n  // `/wait-for-init`. This might fail because the server is still starting up\n  // and is not listening on that port yet. In that case we wait 2 seconds and\n  // retry, up to 10 times. If it fails for another reason, we also retry\n  // after 2 seconds. Once we get the 'ok' from the server, we return from\n  // this function. If that doesn't happen after 10 attempts, we throw an\n  // error. At this point it looks like the new server version doesn't work -\n  // abort the deploy!\n  await retryOnError(\n    'Wait for init',\n    async () => {\n      const response = await fetch(\n        `http://${hostname}:${env.STATUS_SERVER_PORT}/wait-for-init`,\n        {\n          // Once we can connect to the server, the start-up is usually super\n          // quick, so we don't expect to have to wait for a long time. Don't wait\n          // longer than ten seconds here!\n          signal: AbortSignal.timeout(10 * 1000),\n        },\n      );\n      if (\n        !(\n          response &&\n          response.status === 200 &&\n          (await response.text()) === 'ok'\n        )\n      ) {\n        throw new Error('Received bad response from server');\n      }\n    },\n    {\n      retries: 10,\n      retryDelaySeconds: 2,\n    },\n  );\n}\n\ntype RetryOptions = {\n  retries?: number;\n  retryIf?: (err: any) => boolean;\n  retryDelaySeconds?: number;\n};\n\nasync function retryOnError<T>(\n  operationName: string,\n  operation: () => Promise<T>,\n  options: RetryOptions,\n): Promise<T> {\n  const opts: Required<RetryOptions> = {\n    retries: 3,\n    retryIf: (_) => true,\n    retryDelaySeconds: 5,\n    ...options,\n  };\n  try {\n    return await operation();\n  } catch (err) {\n    if (opts.retries > 0 && opts.retryIf(err)) {\n      log(`${operationName} failed, retrying (retries=${opts.retries})`);\n      await sleepSeconds(opts.retryDelaySeconds);\n      return await retryOnError(operationName, operation, {\n        ...opts,\n        retries: opts.retries - 1,\n      });\n    } else {\n      log(`${operationName} failed:`, inspect(err, false, 10, false));\n      throw err;\n    }\n  }\n}\n\nmain().then(\n  (code) => process.exit(code),\n  (err) => {\n    logError(err);\n    process.exit(1);\n  },\n);\n", "import type { Tier } from 'ops/aws/src/common.ts';\n\n// AWS Environment values\nexport const AWS_REGION = 'eu-west-2';\n\n// Default resource owner, used for tagging resources with tags that Vanta reads\nexport const DEFAULT_OWNER = 'dmmiller@cord.com';\n\n// The user group that is allowed to ssh to EC2 instances\nexport const EC2_INSTANCE_CONNECT_GROUP = 'engineering';\n\n// The email address to send ops notifications to\nexport const OPS_NOTIFICATION_EMAIL = 'YOUR_EMAIL_HERE';\n\n// S3 bucket names have to be globally unique, so prefix all bucket names with\n// this string\nexport const S3_BUCKET_PREFIX = '';\n\n// AWS sets up a default VPC and security group in each region, and you're not\n// able to create replacements with exactly the same properties in CF, so\n// instead we import them by ID.  Replace these with the IDs of the objects that\n// AWS creates for you.\nexport const DEFAULT_VPC_ID = 'vpc-1f773277';\nexport const DEFAULT_SECURITY_GROUP_ID = 'sg-11eaac72';\nexport const DEFAULT_PUBLIC_SUBNET_A_ID = 'subnet-c0ae25ba';\nexport const DEFAULT_PUBLIC_SUBNET_B_ID = 'subnet-f177a9bd';\nexport const DEFAULT_PUBLIC_SUBNET_C_ID = 'subnet-b086c9d9';\nexport const DEFAULT_VPC_ID_US_EAST_1 = 'vpc-54696e2e';\n\n// all the domains under which we serve the product\nexport const CORD_COM_DOMAINS = [\n  'cord.com',\n  'getradical.co',\n  'cord.so',\n  'cord.fyi',\n];\n\n// The domain name we want all requests to be redirected to, and that serves as\n// the base for all other domains (eg, api., app.)\nexport const PRIMARY_DOMAIN_NAME = CORD_COM_DOMAINS[0];\n\n// domains for which we set up gmail\nexport const GMAIL_DOMAINS = ['cord.com', 'cord.so', 'getradical.co'];\n\n// Domain TXT records, for Google site verification and such things\nexport const TXT_RECORDS = {\n  'getradical.co': [\n    'google-site-verification=BtgOe3c6_AitAdNHNDU-2dedVumtkfO5OAHpnUNrEyM',\n  ],\n  'cord.com': [\n    'google-site-verification=o0E3i6wuU7HmxGIf_D7jLS089pFF7l19xfj8OebZ8ds',\n    'google-site-verification=33uewWcG3InRmPHAs8TUHCjGTHZonvQzd7MxjPZSaEo',\n    'OSSRH-82140',\n    'ahrefs-site-verification_4b6190ed0dbc98695c8737c1ad9070106203ccfca7f7cd1f309a73010d2cf744',\n  ],\n  'cord.so': [\n    'google-site-verification=gjiL3OQHqmQnYx7KyujYpX29mEvyyxnCwfRfIMwr1cQ',\n  ],\n};\n\n// Domain keys for DKIM\nexport const DOMAIN_KEYS = {\n  'getradical.co': {\n    // google = Google (our email)\n    google:\n      'v=DKIM1; k=rsa; p=MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA9UaUXI2l/R6DevMnY5lLzBGSmaK3sS5l1TGNMTu/oSlPTEaNJyiDt3b3zNrmoqWpMziPL6O5WwAG+l8CowD7gAnvjHujrIcPyP+EQ2k7+wh2pHk7prgITmTurljQKi2VedEfbRyT4u7UFctazXU0k4axUZGIjiQwrEAWR4ubgg9KEhZrFWPszOKeHTUsF9KahoasIJoPFfDS1FAiDYJcMDXAKg+4RjKM9aH42ADHht/gx98oQe4uwtJuCmfo/IvS5txTdRZMBeQ8Aip4jRRzqzdJVTTzsCE6eOnlsHyIpfWVtHK8uO41Est2s76EhpikVGt3NMRdsbHiJNgVYmmaCwIDAQAB',\n  },\n  'cord.com': {\n    // google = Google (our email)\n    google:\n      'v=DKIM1; k=rsa; p=MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAiwzgkiUn2tEnh417+3ate4MfoK72XsUU2PKXAyQ8BOzmb3AcpnrYcyafFLWGxSZfFvai3F2PcRGe02JWDq2+x7YlS/JICm6vyyofM/F1qu1/YZv2+7xNyDEx0R2ccQGgOXrczX2ecWu7aHnCRWgQB0UtKE/78OYXEvoKeSQnFjmeY2v4KGu1W35gQ9o7Y44jNJrXKrsPTV+iIwuoaqh/F2zsDBgt0izEiiQcSaNJyXx3RKinQDhlKMTCR9gM4yQ4Zmi+S+M4BrZZ6WZD0P1sBiO5vfs4k7zCwWr2c+MLYwPIexw12T6socOtqcAjoHLkZ3gYHCGzNIz3Ct6aM/is4wIDAQAB',\n  },\n  'cord.so': {\n    // google = Google (our email)\n    // random strings: ...amazonses.com = Loops (marketing)\n    google:\n      'v=DKIM1; k=rsa; p=MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAn/NFJgjIFscAVGv8jbgDL0wr+Dh3nJxKAyxy31FyhEzUIJYwEtR9KyQXWeAO7D/sCEQ7dA+Dqum6kuiLc/OSFg4vu8bkYkQb0Vw5+2eQbTKoh/DQ5ju8Txiudd0r0SzQGx7YWzmJcfLPe1Jqa4AaYraZRCLyRDbfdg9bhOxaLJ+aUbX7xZVPEL35RfkW2Stlf3Ny7rl25bHRPFUnJQJflOkldXLZyRknXGP3s6eCXoAH84WVNr5XjPbUEUFwS9/TbDj7QKcQIcAPwRPH8/4arvw2j8nSzZHpVidIVyPO+J8ToUnRia33JT6uvqgsE3jBEQTSJyFOGNXiJ8eu8G/SZQIDAQAB',\n    gw7lwwllla3tk33rzzpi4pkk7b7vzw65:\n      'CNAME:gw7lwwllla3tk33rzzpi4pkk7b7vzw65.dkim.amazonses.com.',\n    jgxjf2ny7ruwqsflekpn27zft64maxn7:\n      'CNAME:jgxjf2ny7ruwqsflekpn27zft64maxn7.dkim.amazonses.com.',\n    wwmfgpjwizpjhbulmahzlx65e22z6oko:\n      'CNAME:wwmfgpjwizpjhbulmahzlx65e22z6oko.dkim.amazonses.com.',\n  },\n  'cord.fyi': {\n    // s1, s2 = Sendgrid (product notifications)\n    s1: 'CNAME:s1.domainkey.u16847044.wl045.sendgrid.net',\n    s2: 'CNAME:s2.domainkey.u16847044.wl045.sendgrid.net',\n  },\n};\n\ntype SpfType = Record<string, string | Record<string, string> | undefined> & {\n  default: string;\n};\n\n// SPF records\nexport const SPF_RECORDS: SpfType = {\n  // _spf.google.com = Google (our email)\n  // amazonses.com = Loops (marketing)\n  // sendgrid.net = Sendgrid (product notifications)\n  default: 'v=spf1 include:_spf.google.com ~all',\n  'cord.com': 'v=spf1 include:_spf.google.com ~all',\n  'cord.so': {\n    '@': 'v=spf1 include:_spf.google.com ~all',\n    envelope: 'v=spf1 include:amazonses.com ~all',\n  },\n  'cord.fyi': 'v=spf1 include:sendgrid.net -all',\n};\n\n// CI/CD values\nexport const ECR_SERVER_REPO_NAME = 'server';\nexport const ECR_ONCALL_REPO_NAME = 'oncall';\n\nexport const SLACK_OAUTH_STATE_SIGNING_SECRET = 'SlackOauthStateSigningSecret';\nexport const SLACK_OAUTH_STATE_SIGNING_KEY_REF_NAME =\n  'SlackOauthStateSigningSecretKey';\n\nexport const SENDGRID_INBOUND_WEBHOOK_SECRET = 'SendgridInboundWebhookSecret';\nexport const SENDGRID_INBOUND_WEBHOOK_SECRET_KEY_REF_NAME =\n  'SendgridInboundWebhookSecretKey';\n\nexport const CORD_COM_WILDCARD_CERTIFICATE_US_EAST_1 =\n  'arn:aws:acm:us-east-1:869934154475:certificate/179f1ac1-4c87-429c-87fd-e3b9a2af4f0b';\nexport const STAGING_CORD_COM_WILDCARD_CERTIFICATE_US_EAST_1 =\n  'arn:aws:acm:us-east-1:869934154475:certificate/6247511e-1ff8-4ca4-a008-b17cb7c1346b';\nexport const LOADTEST_CORD_COM_WILDCARD_CERTIFICATE_US_EAST_1 =\n  'arn:aws:acm:us-east-1:869934154475:certificate/793e84be-608a-4e54-bdee-efadbc068510';\n\ntype ScalingConstraints = {\n  minCapacity: number;\n  maxCapacity: number;\n};\nexport const SERVER_AUTOSCALING_CAPACITY: {\n  [k in Tier]: ScalingConstraints;\n} = {\n  prod: {\n    minCapacity: 6,\n    maxCapacity: 12,\n  },\n  staging: {\n    minCapacity: 2,\n    maxCapacity: 4,\n  },\n  loadtest: {\n    minCapacity: 4,\n    maxCapacity: 4,\n  },\n};\n", "// There is some TypeScript trickery in this file. It is optimised for making\n// the use of `magicEnv` look good. The call to `magicEnv` should look readable\n// and self-explanatory, and the type hints displayed by the IDE should be\n// useful.\n\n// Define types to declare variables as required, optional or having a default\n// value.  If these classes were empty, TypeScript would treat them as\n// interchangeable. By giving them different shapes (i.e. different members),\n// TypeScript will keep them apart.\nclass RequiredVariable {\n  public readonly req = true;\n}\nclass OptionalVariable {\n  public readonly opt = true;\n}\nclass VariableWithDefaultValue {\n  constructor(public readonly defaultValue: string) {}\n}\n\n// These are the helpers that are used by the caller of `magicEnv` to define\n// their environment fields.\nexport const required = new RequiredVariable();\nexport const optional = new OptionalVariable();\n// eslint-disable-next-line @typescript-eslint/no-shadow -- Disabling for pre-existing problems. Please do not copy this comment, and consider fixing this one!\nexport const defaultValue = (defaultValue: string) =>\n  new VariableWithDefaultValue(defaultValue);\n\n// Here comes the main function of this module: `magicEnv`. It takes one\n// parameter: a JavaScript object with string keys and values of type\n// RequiredVariable, OptionalVariable or VariableWithDefaultValue.\n//\n// `magicEnv` is a template function, which is quite important.\n// `EnvDefinitionType` is the specific type of the environment definition.\n// That type must comply with the restriction that it is an object with string\n// keys and those variable types as values.  However, we will need the\n// *specific* type, i.e. a TypeScript type that contains the specific keys with\n// the corresponding value types. We get access to this type by templating this\n// function.\nexport function magicEnv<\n  EnvDefinitionType extends {\n    [key: string]:\n      | RequiredVariable\n      | OptionalVariable\n      | VariableWithDefaultValue;\n  },\n>(\n  processEnv: { [key: string]: string | undefined },\n  envDefinition: EnvDefinitionType,\n) {\n  // Now start constructing the result of this function.\n  const env: Partial<{ [k in keyof EnvDefinitionType]: string }> = {};\n\n  // And now we iterate through the `envDefinition` object, which we received\n  // from the callback function.\n  for (const key of Object.keys(envDefinition) as (string &\n    keyof EnvDefinitionType)[]) {\n    // This is the value from the process environment\n    const value: string | undefined = processEnv[key];\n\n    // This is the value from the definition object at the top\n    const fieldDefinition:\n      | RequiredVariable\n      | OptionalVariable\n      | VariableWithDefaultValue = envDefinition[key];\n\n    if ((fieldDefinition as any).req) {\n      // This is a required variable.\n\n      if (value === undefined) {\n        throw new Error(`Missing key ${key} in environment`);\n      } else {\n        env[key] = value;\n      }\n    } else if ((fieldDefinition as any).opt) {\n      // This is an optional variable. `value` may be a string or undefined.\n\n      env[key] = value;\n    } else {\n      // This is a variable with a default value (the value of\n      // `fieldDefinition`)\n\n      if (value === undefined) {\n        env[key] = (fieldDefinition as VariableWithDefaultValue).defaultValue;\n      } else {\n        env[key] = value;\n      }\n    }\n  }\n\n  // Return the `env` object that we have just constructed, but return with a\n  // special type that we define here: it is an object which contains all the\n  // keys that the definition object has. The value type is `string`, except\n  // for fields that correspond to optional variables, those have type\n  // `string | undefined`. All fields are declared readonly.\n  return env as {\n    readonly [k in keyof EnvDefinitionType]: EnvDefinitionType[k] extends OptionalVariable\n      ? string | undefined\n      : string;\n  };\n}\n", "import {\n  magicEnv,\n  required,\n  optional,\n  defaultValue,\n} from 'server/src/config/MagicEnv.ts';\n\nexport default magicEnv(process.env, {\n  // `process.env.NODE_ENV` is used in our code, but also in many third party\n  // libraries we import, to switch between development and production mode.\n  // Just to make sure it is set in the process environment, we include it here.\n  NODE_ENV: required,\n\n  // Normally one of `prod`, `staging`, `dev`, `test`, or `loadtest`\n  CORD_TIER: required,\n\n  // Accept connections on these ports\n  API_SERVER_PORT: optional,\n  ADMIN_SERVER_PORT: optional,\n  METRICS_SERVER_PORT: optional,\n  STATUS_SERVER_PORT: optional,\n  CONSOLE_SERVER_PORT: optional,\n  DOCS_SERVER_PORT: optional,\n\n  // PostgreSQL connection configuration - required\n  POSTGRES_HOST: required,\n  POSTGRES_PORT: required,\n  POSTGRES_USER: required,\n  POSTGRES_PASSWORD: required,\n  POSTGRES_DB: required,\n\n  // PostgreSQL read-only server, if there is one (user/password/db setting same\n  // as above)\n  POSTGRES_READ_HOST: optional,\n  POSTGRES_READ_PORT: optional,\n\n  // Redis connection configuration\n  REDIS_PORT: required,\n  REDIS_HOST: required,\n  PREDIS_PORT: required,\n  PREDIS_HOST: required,\n\n  // URLs pointing to our own endpoints\n  TOP_SERVER_HOST: required,\n  APP_SERVER_HOST: required,\n  API_SERVER_HOST: required,\n  API_SERVER_HOST_PRODUCTION: required,\n  ADMIN_SERVER_HOST: required,\n  MARKETING_SERVER_HOST: required,\n  PUBLIC_UPLOADS_HOST: required,\n  CONSOLE_SERVER_HOST: required,\n  CORD_TO_HOST: required,\n  DOCS_SERVER_HOST: required,\n  CLACK_SERVER_HOST: optional,\n  COMMUNITY_SERVER_HOST: required,\n\n  // Slack App credentials - required\n  SLACK_APP_CLIENT_SECRET: required,\n  SLACK_DEV_APP_CLIENT_SECRET: required,\n  SLACK_ADMIN_LOGIN_REDIRECT_HOST: optional,\n  SLACK_APP_REDIRECT_HOST: optional,\n  SLACK_SIGNING_SECRET: required,\n  SLACK_ADMIN_CLIENT_SECRET: required,\n  SLACK_ADMIN_SIGNING_SECRET: required,\n  SLACK_INTERNAL_BOT_TOKEN: required,\n  SLACK_INTERNAL_SIGNING_SECRET: required,\n  SLACK_CUSTOMER_UPDATES_BOT_TOKEN: required,\n\n  // S3 Bucket File storage\n  S3_ACCESS_KEY_ID: optional,\n  S3_ACCESS_KEY_SECRET: optional,\n  S3_REGION: required,\n  S3_BUCKET: required,\n  S3_PUBLIC_BUCKET: required,\n  S3_ENDPOINT: required,\n  S3_USE_PATH_BASED_URLS: required,\n\n  EMAIL_LINKS_TOKEN_SECRET: required,\n\n  // Jira App credentials - required\n  JIRA_APP_CLIENT_ID: required,\n  JIRA_APP_CLIENT_SECRET: required,\n\n  // Asana App credentials - required\n  ASANA_APP_CLIENT_ID: required,\n  ASANA_APP_CLIENT_SECRET: required,\n\n  // Linear App credentials - required\n  LINEAR_APP_CLIENT_ID: required,\n  LINEAR_APP_CLIENT_SECRET: required,\n\n  // Trello App credentials - required\n  TRELLO_APP_CLIENT_ID: required,\n  TRELLO_APP_CLIENT_SECRET: required,\n\n  // Monday App credentials - required\n  MONDAY_APP_CLIENT_ID: required,\n  MONDAY_APP_CLIENT_SECRET: required,\n\n  // Secret for session tokens - required\n  JWT_SIGNING_SECRET: required,\n\n  // Secret for signing OAuth flow state variables encoding the user and org IDs\n  OAUTH_STATE_SIGNING_SECRET: required,\n\n  // Secret for signing Slack OAuth flow state variables encoding the user and org IDs\n  SLACK_OAUTH_STATE_SIGNING_SECRET: required,\n\n  // Log level for console logging - optional ('info' if not provided)\n  LOGLEVEL: defaultValue('info'),\n\n  // Post error messages to this Slack channel,\n  CORD_OPS_SLACK_CHANNEL_ID: optional,\n\n  // Post informational changes to prod setup, including deploy and db migration\n  // messages, to this Slack channel\n  PROD_CHANGES_SLACK_CHANNEL_ID: optional,\n\n  // Post security/SOC2 compliance messages to this Slack channel,\n  CORD_SECURITY_SLACK_CHANNEL_ID: optional,\n\n  // Post info about go redirects to this Slack channel\n  CORD_GO_REDIRECTS_SLACK_CHANNEL_ID: optional,\n\n  // Post messages from customers to this Slack channel\n  CORD_ALL_CUSTOMERS_SLACK_CHANNEL_ID: optional,\n\n  // Post client request messages to this Slack channel\n  CORD_CLIENT_REQUESTS_SLACK_CHANNEL_ID: optional,\n\n  // For sending search queries from the docs site to Slack\n  CORD_DOCS_SEARCH_SLACK_CHANNEL_ID: optional,\n\n  // Cloudwatch config - optional. If these are not provided, Cloudwatch\n  // logging is disabled\n  CLOUDWATCH_LOGLEVEL: optional,\n  CLOUDWATCH_AWS_REGION: defaultValue('eu-west-2'), // our default region, London\n  CLOUDWATCH_LOG_GROUP_NAME: optional,\n  CLOUDWATCH_LOG_STREAM_NAME: optional,\n\n  // Host used when developing locally but an externally accessible url is\n  // needed. (example: d92dd1d1fa99.ngrok.io)\n  EXTERNAL_API_HOST_FOR_DEVELOPMENT: optional,\n\n  // path to static files for the admin app\n  ADMIN_SERVER_STATIC_PATH: defaultValue('dist/server/admin'),\n\n  // path to static files for the console app\n  CONSOLE_SERVER_STATIC_PATH: defaultValue('dist/server/console'),\n\n  // path to static files for the docs app\n  DOCS_SERVER_STATIC_PATH: defaultValue('dist/docs/static'),\n\n  // API key used to send transactional email notifications through Sendgrid.\n  SENDGRID_API_KEY: required,\n\n  // HTTP Basic Auth name and password for SendGrid's Inbound Parse webhooks\n  SENDGRID_INBOUND_WEBHOOK_USER: required,\n  SENDGRID_INBOUND_WEBHOOK_PASSWORD: required,\n\n  // API key used to fetch feature flags from LaunchDarkly\n  LAUNCHDARKLY_API_KEY: optional,\n\n  // Number of extra workers to run the api server in: 'auto' makes one per CPU; otherwise a specific number can be used\n  NUM_WORKERS: optional,\n\n  // Encryption key used when storing secrets in the database\n  PLATFORM_SECRETS_ENCRYPTION_KEY: required,\n\n  // Encryption key used when generating file permalinks\n  FILE_PROXY_SIGNING_SECRET_KEY: required,\n\n  // sentry.io environment setting\n  SENTRY_ENVIRONMENT: optional,\n  SENTRY_RELEASE: optional,\n  SENTRY_TRACE_SAMPLE_RATE: optional,\n\n  // Auth0 Environment variables\n  // 1) For SPA application\n  AUTH0_CLIENT_ID: required,\n  AUTH0_CUSTOM_LOGIN_DOMAIN: required,\n\n  // 2) For verifying incoming events\n  AUTH0_WEBHOOK_SECRET: required,\n\n  // 3) For server to server communication\n  AUTH0_MTM_CLIENT_ID: required,\n  AUTH0_MTM_CLIENT_SECRET: required,\n  AUTH0_GENERAL_DOMAIN: required,\n\n  // console.cord.com cord app credentials\n  DEV_CONSOLE_CORD_APP_SECRET: required,\n\n  // secret for signing admin tokens to serve as proof user is logged in to\n  // admin\n  ADMIN_TOKEN_SECRET: required,\n\n  // flag whether the SDK testbed should be built and served\n  INCLUDE_SDK_TESTBED: optional,\n\n  // secret for cookies on the docs web site\n  DOCS_COOKIE_PARSER_SECRET: optional,\n\n  // set email for all notifications when testing with users on testbed\n  TESTBED_USERS_EMAIL: optional,\n\n  // secret for creating searchable embeddings and generating search\n  // results within our docs\n  OPENAI_API_SECRET: required,\n\n  // secret for getting geographic information from an IP address\n  IPSTACK_API_SECRET: optional,\n\n  // Host for where we generate the ai chat bot in the docs\n  DOCS_AI_CHATBOT_SERVER_HOST: required,\n\n  // Google analytic events\n  GA_MEASUREMENT_ID: required,\n  GA_MEASUREMENT_PROTOCOL_API_SECRET: required,\n\n  // secret for stripe\n  STRIPE_SECRET_KEY: required,\n  STRIPE_WEBHOOK_SECRET_KEY: required,\n\n  DEMO_APPS_SHARED_SECRET: required,\n\n  // loops.so for sending newletters\n  LOOPS_SO_API_KEY: required,\n});\n", "import * as child_process from 'child_process';\n\nimport * as Slack from '@slack/web-api';\nimport pg from 'pg';\n\nimport env from 'server/src/config/Env.ts';\nimport sleep from 'common/util/sleep.ts';\n\n/**\n * Run a command line and return the exit code\n */\nexport function runCommandLine(\n  cmd: string,\n  args: string[],\n  options: child_process.SpawnOptions = {},\n  stdin?: string,\n): Promise<number | null> {\n  console.log(`Executing command:\\n  ${cmd} ${args.join(' ')}\\n`);\n  return new Promise<number | null>((resolve, reject) => {\n    const proc = child_process.spawn(cmd, args, {\n      stdio: [stdin === undefined ? 'ignore' : 'pipe', 'inherit', 'inherit'],\n      ...options,\n    });\n    if (stdin !== undefined && proc.stdin) {\n      const stream = proc.stdin;\n      stream.write(stdin, 'utf-8', () => stream.end());\n    }\n    proc.on('error', reject);\n    proc.once('close', (code) => resolve(code));\n  });\n}\n\nexport async function connectToDatabase() {\n  const clientConfig: pg.ClientConfig = {\n    user: env.POSTGRES_USER,\n    host: env.POSTGRES_HOST,\n    database: env.POSTGRES_DB,\n    password: env.POSTGRES_PASSWORD,\n    port:\n      env.POSTGRES_PORT !== undefined ? Number(env.POSTGRES_PORT) : undefined,\n  };\n\n  const client = new pg.Client(clientConfig);\n  await client.connect();\n  return client;\n}\n\nexport async function postMessageFactory(slackChannelID: string | undefined) {\n  if (slackChannelID) {\n    try {\n      const token = env.SLACK_INTERNAL_BOT_TOKEN;\n      let prefix = '';\n\n      const {\n        GITHUB_REPOSITORY,\n        GITHUB_RUN_ID,\n        GITHUB_RUN_NUMBER,\n        GITHUB_SERVER_URL,\n      } = process.env;\n      if (\n        GITHUB_REPOSITORY &&\n        GITHUB_RUN_ID &&\n        GITHUB_RUN_NUMBER &&\n        GITHUB_SERVER_URL\n      ) {\n        prefix = `[<${GITHUB_SERVER_URL}/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}|#${GITHUB_RUN_NUMBER}>] `;\n      }\n\n      const slackClient = new Slack.WebClient(token);\n      return async (text: string) => {\n        try {\n          await slackClient.chat.postMessage({\n            channel: slackChannelID,\n            text: prefix + text,\n          });\n        } catch (err) {\n          console.error(`Error posting message to Slack: ${text}`, err);\n        }\n      };\n    } catch (err) {\n      console.error('Cannot post messages to Slack:', err);\n    }\n  }\n  return (text: string) => {\n    console.log(text);\n    return Promise.resolve();\n  };\n}\n\nexport const sleepSeconds = (seconds: number) => sleep(seconds * 1000);\n", "export default function sleep(ms: number): Promise<void> {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n}\n"],
  "mappings": ";;;AAEA,SAAS,SAAS,iBAAiB;AAEnC,OAAO;AACP,YAAY,QAAQ;AACpB,YAAY,UAAU;AACtB,YAAY,iBAAiB;AAC7B,YAAY,gBAAgB;AAC5B,YAAY,SAAS;AACrB,YAAY,SAAS;AACrB,YAAY,WAAW;AACvB,OAAO,YAAY;AACnB,SAAS,cAAc;AAEvB,OAAO,WAAW;;;ACZX,IAAM,aAAa;AA2BnB,IAAM,mBAAmB;AAAA,EAC9B;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAIO,IAAM,sBAAsB,iBAAiB,CAAC;;;AC9BrD,IAAM,mBAAN,MAAuB;AAAA,EAAvB;AACE,SAAgB,MAAM;AAAA;AACxB;AACA,IAAM,mBAAN,MAAuB;AAAA,EAAvB;AACE,SAAgB,MAAM;AAAA;AACxB;AACA,IAAM,2BAAN,MAA+B;AAAA,EAC7B,YAA4BA,eAAsB;AAAtB,wBAAAA;AAAA,EAAuB;AACrD;AAIO,IAAM,WAAW,IAAI,iBAAiB;AACtC,IAAM,WAAW,IAAI,iBAAiB;AAEtC,IAAM,eAAe,CAACA,kBAC3B,IAAI,yBAAyBA,aAAY;AAapC,SAAS,SAQd,YACA,eACA;AAEA,QAAM,MAA2D,CAAC;AAIlE,aAAW,OAAO,OAAO,KAAK,aAAa,GACb;AAE5B,UAAM,QAA4B,WAAW,GAAG;AAGhD,UAAM,kBAGyB,cAAc,GAAG;AAEhD,QAAK,gBAAwB,KAAK;AAGhC,UAAI,UAAU,QAAW;AACvB,cAAM,IAAI,MAAM,eAAe,GAAG,iBAAiB;AAAA,MACrD,OAAO;AACL,YAAI,GAAG,IAAI;AAAA,MACb;AAAA,IACF,WAAY,gBAAwB,KAAK;AAGvC,UAAI,GAAG,IAAI;AAAA,IACb,OAAO;AAIL,UAAI,UAAU,QAAW;AACvB,YAAI,GAAG,IAAK,gBAA6C;AAAA,MAC3D,OAAO;AACL,YAAI,GAAG,IAAI;AAAA,MACb;AAAA,IACF;AAAA,EACF;AAOA,SAAO;AAKT;;;AC5FA,IAAO,cAAQ,SAAS,QAAQ,KAAK;AAAA;AAAA;AAAA;AAAA,EAInC,UAAU;AAAA;AAAA,EAGV,WAAW;AAAA;AAAA,EAGX,iBAAiB;AAAA,EACjB,mBAAmB;AAAA,EACnB,qBAAqB;AAAA,EACrB,oBAAoB;AAAA,EACpB,qBAAqB;AAAA,EACrB,kBAAkB;AAAA;AAAA,EAGlB,eAAe;AAAA,EACf,eAAe;AAAA,EACf,eAAe;AAAA,EACf,mBAAmB;AAAA,EACnB,aAAa;AAAA;AAAA;AAAA,EAIb,oBAAoB;AAAA,EACpB,oBAAoB;AAAA;AAAA,EAGpB,YAAY;AAAA,EACZ,YAAY;AAAA,EACZ,aAAa;AAAA,EACb,aAAa;AAAA;AAAA,EAGb,iBAAiB;AAAA,EACjB,iBAAiB;AAAA,EACjB,iBAAiB;AAAA,EACjB,4BAA4B;AAAA,EAC5B,mBAAmB;AAAA,EACnB,uBAAuB;AAAA,EACvB,qBAAqB;AAAA,EACrB,qBAAqB;AAAA,EACrB,cAAc;AAAA,EACd,kBAAkB;AAAA,EAClB,mBAAmB;AAAA,EACnB,uBAAuB;AAAA;AAAA,EAGvB,yBAAyB;AAAA,EACzB,6BAA6B;AAAA,EAC7B,iCAAiC;AAAA,EACjC,yBAAyB;AAAA,EACzB,sBAAsB;AAAA,EACtB,2BAA2B;AAAA,EAC3B,4BAA4B;AAAA,EAC5B,0BAA0B;AAAA,EAC1B,+BAA+B;AAAA,EAC/B,kCAAkC;AAAA;AAAA,EAGlC,kBAAkB;AAAA,EAClB,sBAAsB;AAAA,EACtB,WAAW;AAAA,EACX,WAAW;AAAA,EACX,kBAAkB;AAAA,EAClB,aAAa;AAAA,EACb,wBAAwB;AAAA,EAExB,0BAA0B;AAAA;AAAA,EAG1B,oBAAoB;AAAA,EACpB,wBAAwB;AAAA;AAAA,EAGxB,qBAAqB;AAAA,EACrB,yBAAyB;AAAA;AAAA,EAGzB,sBAAsB;AAAA,EACtB,0BAA0B;AAAA;AAAA,EAG1B,sBAAsB;AAAA,EACtB,0BAA0B;AAAA;AAAA,EAG1B,sBAAsB;AAAA,EACtB,0BAA0B;AAAA;AAAA,EAG1B,oBAAoB;AAAA;AAAA,EAGpB,4BAA4B;AAAA;AAAA,EAG5B,kCAAkC;AAAA;AAAA,EAGlC,UAAU,aAAa,MAAM;AAAA;AAAA,EAG7B,2BAA2B;AAAA;AAAA;AAAA,EAI3B,+BAA+B;AAAA;AAAA,EAG/B,gCAAgC;AAAA;AAAA,EAGhC,oCAAoC;AAAA;AAAA,EAGpC,qCAAqC;AAAA;AAAA,EAGrC,uCAAuC;AAAA;AAAA,EAGvC,mCAAmC;AAAA;AAAA;AAAA,EAInC,qBAAqB;AAAA,EACrB,uBAAuB,aAAa,WAAW;AAAA;AAAA,EAC/C,2BAA2B;AAAA,EAC3B,4BAA4B;AAAA;AAAA;AAAA,EAI5B,mCAAmC;AAAA;AAAA,EAGnC,0BAA0B,aAAa,mBAAmB;AAAA;AAAA,EAG1D,4BAA4B,aAAa,qBAAqB;AAAA;AAAA,EAG9D,yBAAyB,aAAa,kBAAkB;AAAA;AAAA,EAGxD,kBAAkB;AAAA;AAAA,EAGlB,+BAA+B;AAAA,EAC/B,mCAAmC;AAAA;AAAA,EAGnC,sBAAsB;AAAA;AAAA,EAGtB,aAAa;AAAA;AAAA,EAGb,iCAAiC;AAAA;AAAA,EAGjC,+BAA+B;AAAA;AAAA,EAG/B,oBAAoB;AAAA,EACpB,gBAAgB;AAAA,EAChB,0BAA0B;AAAA;AAAA;AAAA,EAI1B,iBAAiB;AAAA,EACjB,2BAA2B;AAAA;AAAA,EAG3B,sBAAsB;AAAA;AAAA,EAGtB,qBAAqB;AAAA,EACrB,yBAAyB;AAAA,EACzB,sBAAsB;AAAA;AAAA,EAGtB,6BAA6B;AAAA;AAAA;AAAA,EAI7B,oBAAoB;AAAA;AAAA,EAGpB,qBAAqB;AAAA;AAAA,EAGrB,2BAA2B;AAAA;AAAA,EAG3B,qBAAqB;AAAA;AAAA;AAAA,EAIrB,mBAAmB;AAAA;AAAA,EAGnB,oBAAoB;AAAA;AAAA,EAGpB,6BAA6B;AAAA;AAAA,EAG7B,mBAAmB;AAAA,EACnB,oCAAoC;AAAA;AAAA,EAGpC,mBAAmB;AAAA,EACnB,2BAA2B;AAAA,EAE3B,yBAAyB;AAAA;AAAA,EAGzB,kBAAkB;AACpB,CAAC;;;ACpOD,YAAY,mBAAmB;AAE/B,YAAY,WAAW;AACvB,OAAO,QAAQ;;;ACHA,SAAR,MAAuB,IAA2B;AACvD,SAAO,IAAI,QAAQ,CAAC,YAAY,WAAW,SAAS,EAAE,CAAC;AACzD;;;ADSO,SAAS,eACd,KACA,MACA,UAAsC,CAAC,GACvC,OACwB;AACxB,UAAQ,IAAI;AAAA,IAAyB,GAAG,IAAI,KAAK,KAAK,GAAG,CAAC;AAAA,CAAI;AAC9D,SAAO,IAAI,QAAuB,CAAC,SAAS,WAAW;AACrD,UAAM,OAAqB,oBAAM,KAAK,MAAM;AAAA,MAC1C,OAAO,CAAC,UAAU,SAAY,WAAW,QAAQ,WAAW,SAAS;AAAA,MACrE,GAAG;AAAA,IACL,CAAC;AACD,QAAI,UAAU,UAAa,KAAK,OAAO;AACrC,YAAM,SAAS,KAAK;AACpB,aAAO,MAAM,OAAO,SAAS,MAAM,OAAO,IAAI,CAAC;AAAA,IACjD;AACA,SAAK,GAAG,SAAS,MAAM;AACvB,SAAK,KAAK,SAAS,CAAC,SAAS,QAAQ,IAAI,CAAC;AAAA,EAC5C,CAAC;AACH;AAEA,eAAsB,oBAAoB;AACxC,QAAM,eAAgC;AAAA,IACpC,MAAM,YAAI;AAAA,IACV,MAAM,YAAI;AAAA,IACV,UAAU,YAAI;AAAA,IACd,UAAU,YAAI;AAAA,IACd,MACE,YAAI,kBAAkB,SAAY,OAAO,YAAI,aAAa,IAAI;AAAA,EAClE;AAEA,QAAM,SAAS,IAAI,GAAG,OAAO,YAAY;AACzC,QAAM,OAAO,QAAQ;AACrB,SAAO;AACT;AAEA,eAAsB,mBAAmB,gBAAoC;AAC3E,MAAI,gBAAgB;AAClB,QAAI;AACF,YAAM,QAAQ,YAAI;AAClB,UAAI,SAAS;AAEb,YAAM;AAAA,QACJ;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,MACF,IAAI,QAAQ;AACZ,UACE,qBACA,iBACA,qBACA,mBACA;AACA,iBAAS,KAAK,iBAAiB,IAAI,iBAAiB,iBAAiB,aAAa,KAAK,iBAAiB;AAAA,MAC1G;AAEA,YAAM,cAAc,IAAU,gBAAU,KAAK;AAC7C,aAAO,OAAO,SAAiB;AAC7B,YAAI;AACF,gBAAM,YAAY,KAAK,YAAY;AAAA,YACjC,SAAS;AAAA,YACT,MAAM,SAAS;AAAA,UACjB,CAAC;AAAA,QACH,SAAS,KAAK;AACZ,kBAAQ,MAAM,mCAAmC,IAAI,IAAI,GAAG;AAAA,QAC9D;AAAA,MACF;AAAA,IACF,SAAS,KAAK;AACZ,cAAQ,MAAM,kCAAkC,GAAG;AAAA,IACrD;AAAA,EACF;AACA,SAAO,CAAC,SAAiB;AACvB,YAAQ,IAAI,IAAI;AAChB,WAAO,QAAQ,QAAQ;AAAA,EACzB;AACF;AAEO,IAAM,eAAe,CAAC,YAAoB,MAAM,UAAU,GAAI;;;AJ/DrE,SAAS,OAAO,OAAoB;AAClC,QAAM,MAAK,oBAAI,KAAK,GAAE,YAAY;AAClC,UAAQ,IAAI,IAAI,EAAE,KAAK,GAAG,KAAK;AACjC;AAEA,SAAS,YAAY,OAAc;AACjC,MAAI,UAAU,GAAG,KAAK;AACxB;AAUA,IAAM,SAAS;AAAA,EACb,MAAM;AAAA,IACJ,cAAc;AAAA,MACZ,KAAK;AAAA,MACL,SACE;AAAA,MACF,MAAM;AAAA,MACN,OACE;AAAA,IACJ;AAAA,IACA,0BAA0B;AAAA,EAC5B;AAAA,EACA,SAAS;AAAA,IACP,cAAc;AAAA,MACZ,KAAK;AAAA,MACL,SACE;AAAA,MACF,MAAM;AAAA,MACN,OACE;AAAA,IACJ;AAAA,IACA,0BAA0B;AAAA,EAC5B;AAAA,EACA,UAAU;AAAA,IACR,cAAc;AAAA,MACZ,KAAK;AAAA,IACP;AAAA,IACA,0BAA0B;AAAA,EAC5B;AACF;AAEA,IAAM,OAAO,MAAM,QAAQ,KAAK,MAAM,CAAC,CAAC,EACrC,OAAO,aAAa;AAAA,EACnB,MAAM;AAAA,EACN,aAAa;AAAA,EACb,SAAS;AACX,CAAC,EACA,OAAO,iBAAiB;AAAA,EACvB,MAAM;AAAA,EACN,aAAa;AACf,CAAC,EACA,OAAO,SAAS;AAAA,EACf,MAAM;AAAA,EACN,aAAa;AACf,CAAC,EACA,OAAO,cAAc;AAAA,EACpB,MAAM;AAAA,EACN,aACE;AACJ,CAAC,EACA,KAAK,EACL,MAAM,QAAQ,GAAG,EAAE;AAEtB,eAAe,OAAwB;AACrC,QAAM,EAAE,WAAW,KAAK,IAAI;AAE5B,MAAI,SAAS,aAAa,SAAS,UAAU,SAAS,YAAY;AAChE,UAAM,IAAI,MAAM,yCAAyC;AAAA,EAC3D;AAGA,QAAM,KAAK,MAAM,kBAAkB;AAGnC,QAAM,aAEF,MAAM,GAAG;AAAA,IACP;AAAA;AAAA,IAEA,CAAC,IAAI;AAAA,EACP,IACC,KAAK,CAAC,GAAG,UAAU,CAAC;AAGzB,QAAM,mBAAmB,MAAM;AAAA,IAC7B,YAAI;AAAA,EACN;AAEA,QAAM,kBAAkB,MAAM;AAAA,IAC5B,YAAI;AAAA,EACN;AAEA,MAAI;AACF,UAAM,WAAW,MAAM;AAAA,MACrB;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF;AACA,WAAO;AAAA,EACT,SAAS,KAAK;AACZ,UAAM,iBAAiB,kBAAkB,IAAI;AAAA;AAAA,EAE/C,QAAQ,KAAK,OAAO,IAAI,KAAK,CAAC;AAAA,OACzB;AACH,UAAM;AAAA,EACR;AACF;AAEA,eAAe,WACb,MACA,kBACA,iBACA,WACA,IACA;AACA,MAAI,gBAAgB,IAAI,OAAO;AAC/B,MAAI,cAAc,KAAK,UAAU,MAAM,MAAM,CAAC,CAAC,EAAE;AAEjD,QAAM,WAAW,IAAgB,8BAAkB,EAAE,QAAQ,WAAW,CAAC;AACzE,QAAM,YAAY,IAAQ,cAAU,EAAE,QAAQ,WAAW,CAAC;AAC1D,QAAM,YAAY,IAAQ,cAAU,EAAE,QAAQ,WAAW,CAAC;AAC1D,QAAM,cAAc,IAAU,mCAA6B;AAAA,IACzD,QAAQ;AAAA,EACV,CAAC;AAED,QAAM,cAAc,IAAI,OAAO;AAG/B,QAAM,UAAU,MAAM,WAAW,SAAS;AAM1C,QAAM,WAAW,aAAa,KAAK,WAAW,OAAO;AAOrD,QAAM,YAAY,MAAM,YAAY,SAAS,KAAK,SAAS,EAAE,QAAQ;AACrE,QAAM,YAAY,UAAU,YAAY,CAAC,KAAK,KAAK;AACnD,QAAM,cACJ,UAAU,OAAO;AACnB,QAAM,gBAAgB,YAAY,0BAA0B;AAC5D,QAAM,iBAAiB,YAAY,2BAA2B;AAC9D,QAAM,iBAAiB,YAAY,kBAAkB;AACrD;AAAA,IACE,sBAAsB,SAAS,sBAAsB,aAAa,sBAAsB,cAAc;AAAA,EACxG;AAKA,MAAI,CAAC,KAAK,SAAS,CAAC,UAAU,iBAAiB;AAC7C;AAAA,MACE;AAAA,IACF;AACA,QAAI,KAAK,YAAY;AACnB,YAAM,iBAAiB,qBAAqB,IAAI;AAAA,qBAE9C,gBACI,+CAA+C,aAAa,IAAI,cAAc;AAAA,QAC5E;AAAA,QACA;AAAA,MACF,CAAC,MACD,SACN,IAAI,kBAAkB,EAAE;AAAA,0BACT,cAAc;AAAA,kBACtB,SAAS;AAAA,6CACkB,YAAI,iBAAiB;AAAA,mDACf,IAAI,KAAK,SAAS,KAAK;AAAA,IACjE;AACA,WAAO;AAAA,EACT;AAIA,QAAM;AAAA,IACJ,MAAM,CAAC,EAAE,IAAI,SAAS,CAAC;AAAA,EACzB,IAAI,MAAM,GAAG;AAAA,IACX;AAAA;AAAA;AAAA,IAGA,CAAC,MAAM,iBAAiB,MAAM,WAAW,kBAAkB,IAAI;AAAA,EACjE;AACA,MAAI,iBAAiB,QAAQ,yBAAyB;AAEtD,SAAO,YAAY;AAGjB,UAAM,YAAY,MAAM;AAAA,MACtB,GAAG,IAAI;AAAA,MACP;AAAA,MACA;AAAA,IACF;AAEA,QAAI,gBAAgB;AACpB,eAAW,KAAK,WAAW;AACzB,UAAI,OAAO,EAAE,UAAU,KAAK,EAAE,cAAc,GAAG;AAAA,IACjD;AAGA,UAAM,QAAQ;AAAA,MACZ,UAAU,IAAI,OAAO,aAAa;AAChC,YAAI,kBAAkB,SAAS,UAAU,EAAE;AAC3C,cAAM,eAAe,IAAI,OAAO;AAAA,UAC9B,MAAM,SAAS;AAAA,UACf,MAAM;AAAA,UACN,UAAU;AAAA,QACZ,CAAC;AACD,YAAI,mBAAmB,SAAS,UAAU,EAAE;AAE5C,cAAM,aACH,YAAY;AAAA,UACX,SAAS,KAAK,UAAU;AAAA,YACtB,OAAO,EAAE,MAAM,KAAK;AAAA,YACpB,UAAU,EAAE,OAAO,KAAK;AAAA,UAC1B,CAAC;AAAA,QACH,CAAC,EACA,MAAM,GAAG;AACZ,YAAI,qBAAqB,SAAS,OAAO,SAAS,UAAU,EAAE;AAC9D,cAAM,WAAW,cAAc,WAAW,OAAO;AACjD,YAAI,KAAK,cAAc,WAAW;AAChC,cAAI,cAAc,SAAS,OAAO,KAAK,SAAS,EAAE;AAgBlD,gBAAM,UAAU,cAAc,WAAW,KAAK,SAAS;AAAA,QACzD;AAEA,YAAI,2BAA2B,SAAS,UAAU,EAAE;AAAA,MACtD,CAAC;AAAA,IACH;AAIA,eAAW,YAAY,WAAW;AAChC,UAAI;AAAA;AAAA,YAAiB,SAAS,UAAU,KAAK,SAAS,cAAc,GAAG;AAGvE,UAAI,kBACF,MAAM,kBAAkB,OAAO,IAAI,EAAE,aAAa,KAAK,WAAW,GAClE,SAAS,UAAW;AAEtB,UAAI,mBAAmB,WAAW;AAEhC,YAAI,iCAAiC,cAAc,EAAE;AACrD,aAAK,iBAAiB,wBAAwB,IAAI;AAAA;AAAA,eAE3C,SAAS,UAAU;AAAA,aACrB,SAAS,cAAc;AAAA,iBACnB,cAAc;AAAA;AAAA,CAE9B;AACO;AAAA,MACF;AAGA,iBAAW,CAAC,MAAM,GAAG,KAAK,OAAO,QAAQ,OAAO,IAAI,EAAE,YAAY,GAAG;AACnE,WAAG;AACD,cAAI,oCAAoC,IAAI,kBAAkB;AAC9D,gBAAM,YAAY;AAAA,YAChB,IAAU,+BAAyB;AAAA,cACjC,gBAAgB;AAAA,cAChB,SAAS,CAAC,EAAE,IAAI,SAAS,WAAY,CAAC;AAAA,YACxC,CAAC;AAAA,UACH;AAGA,gBAAM,aAAa,CAAC;AAEpB,4BAAkB,MAAM,kBAAkB,KAAK,WAAW,GACxD,SAAS,UACX;AACA,cAAI,2BAA2B,cAAc,EAAE;AAAA,QACjD,SAAS,mBAAmB;AAAA,MAC9B;AAOA,UAAI,QAAQ,IAAI,sBAAsB,QAAQ;AAC5C,YAAI,4DAA4D;AAAA,MAClE,OAAO;AACL,YAAI,2DAA2D;AAC/D,cAAM,aAAa,EAAE;AACrB,YAAI,eAAe;AAAA,MACrB;AAIA,YAAM,eAAe,IAAI,OAAO;AAAA,QAC9B,MAAM,SAAS;AAAA,QACf,MAAM;AAAA,QACN,UAAU;AAAA,MACZ,CAAC;AAED,UAAI;AACF,cAAM,aACH,aAAa,QAAQ,EACrB,OAAO,EAAE,eAAe,EAAE,MAAM,GAAG,EAAE,CAAC;AAAA,MAC3C,SAAS,KAAK;AACZ;AAAA,UACE;AAAA,UACA;AAAA,QACF;AAAA,MACF;AAEA,YAAM,YAAY,SAAS,cAAe;AAE1C,UAAI;AACF,cAAM,aAAa,aAAa,QAAQ,EAAE,KAAK;AAC/C,cAAM,aAAa,aAAa,QAAQ,EAAE,OAAO;AAAA,MACnD,SAAS,KAAK;AAKZ,YAAI,yDAAyD,GAAG;AAAA,MAClE;AAGA,YAAM,YAAY,MAAM,aAAa,gBAAgB;AAAA,QACnD,OAAO;AAAA,QACP,MAAM;AAAA,QACN,aAAa;AAAA,QACb,cAAc;AAAA,QACd,cAAc;AAAA,QACd,KAAK,CAAC,aAAa,IAAI,EAAE;AAAA,QACzB,YAAY;AAAA,UACV,aAAa;AAAA,UACb,eAAe,EAAE,MAAM,SAAS;AAAA,QAClC;AAAA,MACF,CAAC;AACD,YAAM,UAAU,MAAM;AAGtB,YAAM,kBAAkB,SAAS,cAAe;AAGhD,YAAM,QAAQ;AAAA,QACZ,OAAO,OAAO,OAAO,IAAI,EAAE,YAAY,EAAE;AAAA,UAAI,CAAC,QAC5C,YAAY;AAAA,YACV,IAAU,6BAAuB;AAAA,cAC/B,gBAAgB;AAAA,cAChB,SAAS,CAAC,EAAE,IAAI,SAAS,WAAY,CAAC;AAAA,YACxC,CAAC;AAAA,UACH;AAAA,QACF;AAAA,MACF;AAIA,iBAAS;AACP,cAAM,aAAa,CAAC;AACpB,0BACE,MAAM,kBAAkB,OAAO,IAAI,EAAE,aAAa,KAAK,WAAW,GAClE,SAAS,UAAW;AAEtB,YAAI,oBAAoB,cAAc,EAAE;AAOxC,YAAI,mBAAmB,WAAW;AAChC,cAAI,0BAA0B;AAC9B;AAAA,QACF,WAAW,mBAAmB,WAAW;AACvC;AAAA,YACE,uCAAuC,cAAc;AAAA,UACvD;AACA,eAAK,iBAAiB,wBAAwB,IAAI;AAAA;AAAA,eAE7C,SAAS,UAAU;AAAA,aACrB,SAAS,cAAc;AAAA,iBACnB,cAAc;AAAA;AAAA,CAE9B;AACS;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAGA,QAAI,MAAM,cAAc,IAAI,KAAK,kBAAkB,EAAE,GACnD,gBACI,iDAAiD,aAAa,IAAI,cAAc;AAAA,MAC9E;AAAA,MACA;AAAA,IACF,CAAC,OACD,EACN;AAAA,0BACiB,cAAc;AAAA,kBACtB,SAAS;AAElB,QAAI;AACF,YAAM,WAAW,UAAe,mBAAc;AAC9C,YAAM,MAAM,MAAS;AAAA,QACnB,QAAQ,IAAI;AAAA,MACd;AACA,YAAM,aAAa,MAAM,SAAS,GAAG;AAErC,YAAM,WAAW,IAAI;AACrB,YAAM,qBAAqB,WAAW;AAEtC,YAAM,GAAG;AAAA,QACP;AAAA,QACA,CAAC,UAAU,oBAAoB,QAAQ;AAAA,MACzC;AACA,aAAO;AAAA,mBACC,QAAQ,WAAW,kBAAkB;AAAA,IAC/C,SAAS,KAAK;AACZ,UAAI,+BAA+B,GAAG;AAAA,IACxC;AAEA,UAAM,gBAAgB,GAAG;AAMzB,QAAI;AACF,UAAI,6BAA6B;AACjC,YAAM,QAAQ,IAAI;AAAA,QAChB,eAAe,OAAO;AAAA,UACpB;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA,QAAQ,IAAI;AAAA,UACZ,QAAQ,YAAI,eAAe;AAAA,QAC7B,CAAC;AAAA,QACD,eAAe,OAAO;AAAA,UACpB;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA,QAAQ,IAAI;AAAA,UACZ,QAAQ,YAAI,eAAe;AAAA,QAC7B,CAAC;AAAA,MACH,CAAC,EAAE,KAAK,CAAC,UAAU;AACjB,YAAI,MAAM,CAAC,MAAM,KAAK,MAAM,CAAC,MAAM,GAAG;AACpC,gBAAM,IAAI,MAAM,qCAAqC,KAAK,EAAE;AAAA,QAC9D;AAAA,MACF,CAAC;AAAA,IACH,SAAS,KAAK;AACZ,YAAM,iBAAiB;AAAA;AAAA,EAE3B,QAAQ,KAAK,OAAO,IAAI,KAAK,CAAC;AAAA,OACzB;AAAA,IACH;AAGA,QAAI,0BAA0B;AAE9B,QAAI;AACF,YAAM;AAAA,QACJ;AAAA,QACA,YAAY;AACV,gBAAM,mBAAmB,IAAe,4BAAiB;AAAA,YACvD,QAAQ;AAAA,UACV,CAAC;AAED,gBAAM,eAAe,MAAM,iBAAiB;AAAA,YAC1C,IAAe,qCAA0B;AAAA,cACvC,gBAAgB,OAAO,IAAI,EAAE;AAAA,cAC7B,mBAAmB;AAAA,gBACjB,OAAO,EAAE,UAAU,GAAG,OAAO,CAAC,IAAI,EAAE;AAAA,gBACpC,iBAAiB,UAAU,KAAK,IAAI,CAAC;AAAA,cACvC;AAAA,YACF,CAAC;AAAA,UACH;AACA;AAAA,YACE,wCAAwC,aAAa,cAAc,EAAE;AAAA,UACvE;AAAA,QACF;AAAA,QACA;AAAA,UACE,SAAS;AAAA,UACT,SAAS,CAAC,QAAQ,IAAI,SAAS;AAAA,QACjC;AAAA,MACF;AAAA,IACF,SAAS,KAAK;AACZ,YAAM,iBAAiB;AAAA;AAAA,EAE3B,QAAQ,KAAK,OAAO,IAAI,KAAK,CAAC;AAAA,OACzB;AAAA,IAEH;AAMA,QAAI,KAAK,eAAe;AACtB,UAAI;AACF,cAAM,UAAU,aAAa,WAAW,KAAK,aAAa;AAE1D,cAAM,YACH,SAAS,KAAK,aAAa,EAC3B,KAAK,EAAE,YAAY,QAAQ,CAAQ;AAAA,MACxC,SAAS,KAAK;AACZ,cAAM,iBAAiB,4BACrB,KAAK,aACP;AAAA;AAAA,IAEJ,QAAQ,KAAK,OAAO,IAAI,KAAK,CAAC;AAAA,SACzB;AAAA,MACH;AAAA,IACF;AAEA,UAAM,gBAAgB,+BAA+B;AAAA,EACvD,GAAG,EAAE;AAAA,IACH,MACE,GAAG;AAAA,MACD;AAAA,MACA,CAAC,QAAQ;AAAA,IACX;AAAA,IACF,OAAO,UAAU;AACf,UAAI,cAAc;AAClB,UAAI;AACF,sBAAc,QAAQ,KAAK;AAAA,MAC7B,SAAS,GAAG;AACV,sBAAc,GAAG,KAAK;AAAA,MACxB;AACA,YAAM,GAAG;AAAA,QACP;AAAA,QACA,CAAC,aAAa,QAAQ;AAAA,MACxB;AACA,aAAO,MAAM,QAAQ,OAAO,KAAK;AAAA,IACnC;AAAA,EACF;AAKA,QAAM,SACH;AAAA,IACC,IAAgB,yCAA6B;AAAA,MAC3C,sBAAsB,GAAG,IAAI;AAAA,IAC/B,CAAC;AAAA,EACH,EAEC;AAAA,IAAM,CAAC,QACN,IAAI,OAAO,SAAS,kCAChB,OACA,QAAQ,OAAO,GAAG;AAAA,EACxB;AAEF,QAAM,SAAS;AAAA,IACb,IAAgB,wCAA4B;AAAA,MAC1C,sBAAsB,GAAG,IAAI;AAAA,IAC/B,CAAC;AAAA,EACH;AAEA,SAAO;AACT;AAKA,eAAe,6BACb,sBACA,UACA,WACA;AACA,QAAM,EAAE,sBAAsB,YAAY,IAAI,MAAM,SAAS;AAAA,IAC3D,IAAgB,gDAAoC,CAAC,CAAC;AAAA,EACxD;AACA,QAAM,eAAe,eAAe,CAAC,GAClC;AAAA,IACC,CAAC,aACC,SAAS,yBAAyB,wBAClC,SAAS,mBAAmB;AAAA,EAChC,EACC,IAAI,CAAC,aAAa,SAAS,UAAU,EACrC,OAAO,CAAC,MAA4B,MAAM,MAAS;AAEtD,QAAM,WAAW,MAAM,UAAU;AAAA,IAC/B,IAAQ,6BAAyB,EAAE,aAAa,YAAY,CAAC;AAAA,EAC/D;AAEA,UACG,SAAS,gBAAgB,CAAC,GACxB,IAAI,CAAC,gBAAgB,YAAY,aAAa,CAAC,CAAC,EAChD,KAAK,EAEL,OAAO,CAAC,EAAE,YAAY,eAAe,MAAM,cAAc,cAAc;AAE9E;AAKA,eAAe,WAAW,WAA0B;AAClD,QAAM,eAAe,MAAM,UAAU;AAAA,IACnC,IAAQ,iCAA6B,CAAC,CAAC;AAAA,EACzC;AACA,QAAM,QAAQ,aAAa,oBAAoB,CAAC,EAAE;AAElD,MAAI,CAAC,OAAO;AACV,UAAM,IAAI,MAAM,wCAAwC;AAAA,EAC1D;AAEA,QAAM,IAAI,OAAO,KAAK,EAAE,MAAM,GAAG;AAEjC,MAAI,EAAE,WAAW,GAAG;AAClB,UAAM,IAAI,MAAM,+BAA+B;AAAA,EACjD;AAEA,SAAO,EAAE,UAAU,EAAE,CAAC,GAAG,UAAU,EAAE,CAAC,EAAE;AAC1C;AASA,SAAS,WACP,QACA,SACA,MACe;AACf,SAAO;AAAA,IACL;AAAA,IACA,MACE,IAAI;AAAA,MAAc,CAAC,SAAS,WAC1B,OAAO;AAAA,QACL;AAAA,QACA,CAAC;AAAA,QACD,CAAC,KAAK,WAA8C;AAClD,cAAI,UAAU,CAAC,KAAK;AAClB,gBAAI,QAAa;AAIjB,mBAAO,GAAG,QAAQ,CAAC,SAAiB;AAClC,kBAAI,UAAU,QAAW;AACvB,oBAAI;AACF,wBAAM,SAAS,KAAK,MAAM,KAAK,SAAS,OAAO,CAAC;AAChD,sBAAI,OAAO,OAAO;AAChB,4BAAQ,IAAI,MAAM,OAAO,KAAK;AAAA,kBAChC;AAAA,gBAEF,SAASC,MAAU;AACjB,0BAAQA;AAAA,gBACV;AAAA,cACF;AAAA,YACF,CAAC;AACD,mBAAO,KAAK,OAAO,MAAM;AACvB,kBAAI,UAAU,QAAW;AACvB,uBAAO,KAAK;AAAA,cACd,OAAO;AACL,wBAAQ;AAAA,cACV;AAAA,YACF,CAAC;AAAA,UACH,OAAO;AACL,mBAAO,GAAG;AAAA,UACZ;AAAA,QACF;AAAA,QACA;AAAA,MACF;AAAA,IACF;AAAA,IACF;AAAA,MACE,SAAS,CAAC,QAAQ,IAAI,eAAe;AAAA,IACvC;AAAA,EACF;AACF;AAKA,eAAe,UACb,QACA,eACA,QACA;AAIA,QAAM,QAAQ,2BAA2B,KAAK,MAAM;AACpD,MAAI,SAAS,MAAM,QAAQ;AACzB,UAAM,EAAE,MAAM,IAAI,IAAI,MAAM;AAC5B,UAAM,OAAO,SAAS,aAAa,EAAE,IAAI,EAAE,MAAM,IAAI,CAAC;AAAA,EACxD;AACF;AAEA,eAAe,kBACb,gBACA,aACA;AACA,QAAM,WAAW,MAAM,YAAY;AAAA,IACjC,IAAU,kCAA4B;AAAA,MACpC,gBAAgB;AAAA,IAClB,CAAC;AAAA,EACH;AACA,SAAO,OAAO;AAAA,KACX,SAAS,4BAA4B,CAAC,GACpC,IAAI,CAAC,OAAO,CAAC,GAAG,QAAQ,IAAI,GAAG,cAAc,KAAK,CAAC,EACnD,OAAO,CAAC,MAAkC,EAAE,CAAC,KAAK,EAAE,CAAC,CAAC;AAAA,EAC3D;AACF;AAEA,eAAe,YAAY,UAAkB;AAC3C,QAAM,OAAO,OAAO,YAAI,kBAAkB;AAE1C,MAAI,CAAC,OAAO,MAAM,IAAI,GAAG;AACvB,QAAI,sDAAsD;AAC1D,UAAM,WAAW,MAAM;AAAA,MACrB,UAAU,QAAQ,IAAI,YAAI,kBAAkB;AAAA,MAC5C;AAAA,QACE,QAAQ;AAAA;AAAA,QAER,QAAQ,YAAY,QAAQ,KAAK,GAAI;AAAA,MACvC;AAAA,IACF,EAAE,MAAM,CAAC,QAAQ;AACf,eAAS,GAAG;AACZ,aAAO;AAAA,IACT,CAAC;AAED,QACE,YACA,SAAS,WAAW,OACnB,MAAM,SAAS,KAAK,MAAO,eAC5B;AAEA,UAAI,8BAA8B;AAClC;AAAA,IACF;AAAA,EACF;AAIA,MAAI,0CAA0C,QAAQ,gBAAgB;AACtE,QAAM,aAAa,EAAE;AACvB;AAEA,eAAe,kBAAkB,UAAkB;AACjD,QAAM,OAAO,OAAO,YAAI,kBAAkB;AAE1C,MAAI,OAAO,MAAM,IAAI,GAAG;AACtB;AAAA,MACE;AAAA,IACF;AACA,WAAO,MAAM,aAAa,EAAE;AAAA,EAC9B;AAUA,QAAM;AAAA,IACJ;AAAA,IACA,YAAY;AACV,YAAM,WAAW,MAAM;AAAA,QACrB,UAAU,QAAQ,IAAI,YAAI,kBAAkB;AAAA,QAC5C;AAAA;AAAA;AAAA;AAAA,UAIE,QAAQ,YAAY,QAAQ,KAAK,GAAI;AAAA,QACvC;AAAA,MACF;AACA,UACE,EACE,YACA,SAAS,WAAW,OACnB,MAAM,SAAS,KAAK,MAAO,OAE9B;AACA,cAAM,IAAI,MAAM,mCAAmC;AAAA,MACrD;AAAA,IACF;AAAA,IACA;AAAA,MACE,SAAS;AAAA,MACT,mBAAmB;AAAA,IACrB;AAAA,EACF;AACF;AAQA,eAAe,aACb,eACA,WACA,SACY;AACZ,QAAM,OAA+B;AAAA,IACnC,SAAS;AAAA,IACT,SAAS,CAAC,MAAM;AAAA,IAChB,mBAAmB;AAAA,IACnB,GAAG;AAAA,EACL;AACA,MAAI;AACF,WAAO,MAAM,UAAU;AAAA,EACzB,SAAS,KAAK;AACZ,QAAI,KAAK,UAAU,KAAK,KAAK,QAAQ,GAAG,GAAG;AACzC,UAAI,GAAG,aAAa,8BAA8B,KAAK,OAAO,GAAG;AACjE,YAAM,aAAa,KAAK,iBAAiB;AACzC,aAAO,MAAM,aAAa,eAAe,WAAW;AAAA,QAClD,GAAG;AAAA,QACH,SAAS,KAAK,UAAU;AAAA,MAC1B,CAAC;AAAA,IACH,OAAO;AACL,UAAI,GAAG,aAAa,YAAY,QAAQ,KAAK,OAAO,IAAI,KAAK,CAAC;AAC9D,YAAM;AAAA,IACR;AAAA,EACF;AACF;AAEA,KAAK,EAAE;AAAA,EACL,CAAC,SAAS,QAAQ,KAAK,IAAI;AAAA,EAC3B,CAAC,QAAQ;AACP,aAAS,GAAG;AACZ,YAAQ,KAAK,CAAC;AAAA,EAChB;AACF;",
  "names": ["defaultValue", "err"]
}
